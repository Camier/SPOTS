#!/usr/bin/env python3
"""
Instagram Scraping Best Practices Implementation
Based on proven techniques for Haute-Garonne/Occitanie region
"""

import re
import random
import time
from typing import List, Dict, Tuple, Optional
from geopy.geocoders import Nominatim
from geopy.exc import GeocoderTimedOut, GeocoderServiceError
from src.backend.core.logging_config import logger


class InstagramBestPractices:
    """Implements proven best practices for Instagram scraping"""

    def __init__(self):
        # Initialize geocoder with user agent
        self.geolocator = Nominatim(user_agent="occitanie_spots_v2")

        # Proven location patterns for French text
        self.location_patterns = [
            # Near patterns
            r"pr√®s de (?:la |le |l')?([A-Z√â√à][a-z√©√®√™√†√¢√Æ√¥√ª√ß-]+(?:[\s-][A-Z√â√à][a-z√©√®√™√†√¢√Æ√¥√ª√ß-]+)*)",
            r"proche de (?:la |le |l')?([A-Z√â√à][a-z√©√®√™√†√¢√Æ√¥√ª√ß-]+)",
            # At patterns
            r"√† (?:la |le |l')?([A-Z√â√à][a-z√©√®√™√†√¢√Æ√¥√ª√ß-]+)",
            r"au ([A-Z√â√à][a-z√©√®√™√†√¢√Æ√¥√ª√ß-]+)",
            r"aux ([A-Z√â√à][a-z√©√®√™√†√¢√Æ√¥√ª√ß-]+)",
            # Towards patterns
            r"vers (?:la |le |l')?([A-Z√â√à][a-z√©√®√™√†√¢√Æ√¥√ª√ß-]+)",
            r"direction ([A-Z√â√à][a-z√©√®√™√†√¢√Æ√¥√ª√ß-]+)",
            # Specific location types
            r"(Lac\s+(?:de\s+|d')?[A-Z√â√à][a-z√©√®√™√†√¢√Æ√¥√ª√ß-]+)",
            r"(Mont\s+[A-Z√â√à][a-z√©√®√™√†√¢√Æ√¥√ª√ß-]+)",
            r"(Pic\s+(?:de\s+|d')?[A-Z√â√à][a-z√©√®√™√†√¢√Æ√¥√ª√ß-]+)",
            r"(Col\s+(?:de\s+|d')?[A-Z√â√à][a-z√©√®√™√†√¢√Æ√¥√ª√ß-]+)",
            r"(Gorges?\s+(?:de\s+|d')?[A-Z√â√à][a-z√©√®√™√†√¢√Æ√¥√ª√ß-]+)",
            r"(Cascade\s+(?:de\s+|d')?[A-Z√â√à][a-z√©√®√™√†√¢√Æ√¥√ª√ß-]+)",
            r"(Cirque\s+(?:de\s+|d')?[A-Z√â√à][a-z√©√®√™√†√¢√Æ√¥√ª√ß-]+)",
            # Forest patterns
            r"(?:for√™t|For√™t)\s+(?:de\s+|d')?([A-Z√â√à][a-z√©√®√™√†√¢√Æ√¥√ª√ß-]+)",
            r"(?:bois|Bois)\s+(?:de\s+|d')?([A-Z√â√à][a-z√©√®√™√†√¢√Æ√¥√ª√ß-]+)",
            # Generic location at end
            r"(?:^|\s)([A-Z√â√à][a-z√©√®√™√†√¢√Æ√¥√ª√ß-]+(?:[\s-][A-Z√â√à][a-z√©√®√™√†√¢√Æ√¥√ª√ß-]+)*)",
        ]

        # Occitanie bounding box
        self.occitanie_bounds = {"min_lat": 42.5, "max_lat": 44.5, "min_lon": -0.5, "max_lon": 4.5}

        # Known landmarks for validation
        self.known_landmarks = {
            "toulouse": (43.6047, 1.4442),
            "montpellier": (43.6119, 3.8772),
            "bouconne": (43.633202, 1.2133772),
            "saint-b√©at": (42.8983162, 0.6879078),
            "montr√©jeau": (43.0855843, 0.5685313),
            "ram√©e": (43.573483, 1.3621296),
            "tournefeuille": (43.5827846, 1.3466543),
        }

    def extract_location_from_caption(self, caption: str) -> Optional[str]:
        """Extract the primary location name from Instagram caption using proven patterns"""
        locations = self.extract_locations_from_caption(caption)
        return locations[0] if locations else None

    def detect_activities(self, text: str) -> List[str]:
        """Detect outdoor activities from text"""
        activities = []
        activity_keywords = {
            "randonn√©e": ["randonn", "rando", "marche", "trek", "hike"],
            "baignade": ["baigna", "nage", "plong", "swim", "eau"],
            "escalade": ["escala", "grimp", "climb", "voie"],
            "vtt": ["vtt", "v√©lo", "bike", "cycl"],
            "kayak": ["kayak", "cano√´", "paddle", "raft"],
            "camping": ["camp", "bivouac", "tente"],
            "p√™che": ["p√™ch", "poisson", "fish"],
            "sp√©l√©o": ["sp√©l√©o", "grotte", "cave"],
        }

        text_lower = text.lower()
        for activity, keywords in activity_keywords.items():
            if any(keyword in text_lower for keyword in keywords):
                activities.append(activity)

        return activities

    def extract_locations_from_caption(self, caption: str) -> List[str]:
        """Extract location names from Instagram caption using proven patterns"""
        locations = set()

        for pattern in self.location_patterns:
            matches = re.findall(pattern, caption, re.IGNORECASE)
            for match in matches:
                # Clean and normalize location name
                location = match.strip()
                if len(location) > 2 and not location.lower() in ["les", "des", "aux"]:
                    locations.add(location)

        return list(locations)

    def geocode_location(self, location: str, retry_count: int = 3) -> Optional[Tuple[float, float]]:
        """Geocode location with retry logic and Occitanie context"""
        # Check known landmarks first
        location_lower = location.lower()
        if location_lower in self.known_landmarks:
            return self.known_landmarks[location_lower]

        # Add Occitanie context for better results
        search_queries = [
            f"{location}, Occitanie, France",
            f"{location}, Haute-Garonne, France",
            f"{location}, France",
            location,
        ]

        for query in search_queries:
            for attempt in range(retry_count):
                try:
                    # Add delay to respect rate limits
                    time.sleep(1 + attempt * 0.5)

                    result = self.geolocator.geocode(query, timeout=10)
                    if result:
                        lat, lon = result.latitude, result.longitude

                        # Validate within Occitanie bounds
                        if self.is_in_occitanie(lat, lon):
                            return (lat, lon)

                except (GeocoderTimedOut, GeocoderServiceError) as e:
                    if attempt == retry_count - 1:
                        logger.info(f"Geocoding failed for {location}: {e}")

        return None

    def is_in_occitanie(self, lat: float, lon: float) -> bool:
        """Check if coordinates are within Occitanie bounds"""
        return (
            self.occitanie_bounds["min_lat"] <= lat <= self.occitanie_bounds["max_lat"]
            and self.occitanie_bounds["min_lon"] <= lon <= self.occitanie_bounds["max_lon"]
        )

    def get_anti_detection_config(self) -> Dict:
        """Get recommended anti-detection configuration"""
        return {
            "user_agents": [
                "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
                "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36",
            ],
            "viewport_sizes": [
                {"width": 1920, "height": 1080},
                {"width": 1366, "height": 768},
                {"width": 1440, "height": 900},
            ],
            "delays": {
                "between_actions": (2000, 8000),  # 2-8 seconds
                "page_load": (3000, 5000),  # 3-5 seconds
                "scroll": (1000, 3000),  # 1-3 seconds
            },
            "rate_limits": {
                "posts_per_hour": 40,  # Conservative limit
                "delay_between_posts": 90,  # 90 seconds minimum
            },
        }

    def generate_human_like_behavior(self) -> List[Dict]:
        """Generate human-like interaction patterns"""
        behaviors = [
            {
                "action": "mouse_move",
                "x": random.randint(100, 1800),
                "y": random.randint(100, 900),
                "duration": random.randint(500, 1500),
            },
            {"action": "scroll", "direction": random.choice(["down", "up"]), "distance": random.randint(100, 500)},
            {"action": "wait", "duration": random.randint(1000, 3000)},
        ]

        return random.sample(behaviors, k=random.randint(1, 2))

    def validate_scraping_metrics(self, results: List[Dict]) -> Dict:
        """Validate scraping results against best practice metrics"""
        total = len(results)
        locations_detected = sum(1 for r in results if r.get("location"))
        coordinates_found = sum(1 for r in results if r.get("coordinates"))

        # Handle both old tuple format and new dict format for coordinates
        in_occitanie = 0
        for r in results:
            coords = r.get("coordinates")
            if coords:
                if isinstance(coords, dict):
                    # New format: {'lat': x, 'lon': y}
                    if self.is_in_occitanie(coords["lat"], coords["lon"]):
                        in_occitanie += 1
                elif isinstance(coords, (list, tuple)) and len(coords) >= 2:
                    # Old format: [lat, lon] or (lat, lon)
                    if self.is_in_occitanie(coords[0], coords[1]):
                        in_occitanie += 1

        return {
            "total_posts": total,
            "location_detection_rate": (locations_detected / total * 100) if total > 0 else 0,
            "coordinate_accuracy": (coordinates_found / locations_detected * 100) if locations_detected > 0 else 0,
            "occitanie_coverage": (in_occitanie / coordinates_found * 100) if coordinates_found > 0 else 0,
            "success_metrics": {
                "target_detection": 100,  # Target: 100% location detection
                "target_accuracy": 85,  # Target: 85% coordinate accuracy
                "target_false_positive": 5,  # Target: <5% false positives
            },
        }

    def process_instagram_caption(self, caption: str) -> Dict:
        """Complete processing pipeline for Instagram caption"""
        result = {"caption": caption, "locations": [], "coordinates": [], "in_occitanie": False}

        # Extract locations
        locations = self.extract_locations_from_caption(caption)
        result["locations"] = locations

        # Geocode each location
        for location in locations:
            coords = self.geocode_location(location)
            if coords:
                result["coordinates"].append(
                    {
                        "name": location,
                        "lat": coords[0],
                        "lon": coords[1],
                        "in_bounds": self.is_in_occitanie(coords[0], coords[1]),
                    }
                )
                if self.is_in_occitanie(coords[0], coords[1]):
                    result["in_occitanie"] = True

        return result

    def export_spots_data(self, spots: List[Dict], output_file: str) -> None:
        """Export spots data with proper schema including 'source' field"""
        from datetime import datetime
        import json
        from pathlib import Path

        # Create export structure with required 'source' field
        export_data = {
            "export_date": datetime.now().isoformat(),
            "source": "Instagram",  # Required field for schema validation
            "total_spots": len(spots),
            "spots": spots,
        }

        # Ensure exports directory exists
        Path(output_file).parent.mkdir(parents=True, exist_ok=True)

        # Save to file
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(export_data, f, indent=2, ensure_ascii=False)

        logger.info(f"‚úÖ Exported {len(spots)} spots to {output_file}")


def main():
    """Demonstrate best practices usage with validated export"""
    bp = InstagramBestPractices()
    from datetime import datetime

    # Test posts with complete data
    test_posts = [
        {
            "id": "3382721454605055587",
            "caption": "Week-end √† Saint-B√©at, petite rando avec vue sur les montagnes ‚õ∞Ô∏è",
            "timestamp": "2025-08-03T14:30:00Z",
            "likes": 245,
            "url": "https://instagram.com/p/C8zXyS3tL1j",
        },
        {
            "id": "3382721454605055588",
            "caption": "Apr√®s Toulouse, retour sur Ram√©e pour la baignade üèä",
            "timestamp": "2025-08-03T16:45:00Z",
            "likes": 156,
            "url": "https://instagram.com/p/C8zXyS3tL1k",
        },
        {
            "id": "3382721454605055589",
            "caption": "Montr√©jeau sous le soleil ‚òÄÔ∏è Escalade et camping ce week-end! #pyr√©n√©es",
            "timestamp": "2025-08-03T10:15:00Z",
            "likes": 312,
            "url": "https://instagram.com/p/C8zXyS3tL1l",
        },
        {
            "id": "3382721454605055590",
            "caption": "Balade en for√™t de Bouconne, le poumon vert pr√®s de Toulouse üå≤",
            "timestamp": "2025-08-03T09:00:00Z",
            "likes": 89,
            "url": "https://instagram.com/p/C8zXyS3tL1m",
        },
    ]

    logger.info("üéØ Instagram Best Practices Implementation")
    logger.info("=" * 50)

    # Process posts into spots format
    spots = []

    for post in test_posts:
        logger.info(f"\nüìç Processing: {post['caption'][:50]}...")

        # Extract location and activities
        location = bp.extract_location_from_caption(post["caption"])
        activities = bp.detect_activities(post["caption"])

        # Get coordinates
        coordinates = None
        if location:
            coords = bp.geocode_location(location)
            if coords:
                coordinates = {"lat": coords[0], "lon": coords[1]}

        # Create spot in Instagram schema format
        spot = {
            "id": post["id"],
            "caption": post["caption"],
            "timestamp": post["timestamp"],
            "likes": post["likes"],
            "url": post["url"],
            "location": location,
            "coordinates": coordinates,
            "activities": activities,
            "sentiment": "positive" if any(emoji in post["caption"] for emoji in ["üòç", "‚òÄÔ∏è", "üå≤", "‚õ∞Ô∏è"]) else None,
            "collected_at": datetime.now().isoformat(),
        }

        spots.append(spot)

        # Display results
        if location:
            logger.info(f"  ‚úÖ Location: {location}")
        if activities:
            logger.info(f"  üèÉ Activities: {', '.join(activities)}")
        if coordinates:
            logger.info(f"  üìç Coordinates: ({coordinates['lat']:.6f}, {coordinates['lon']:.6f})")

    # Export with validation-ready format
    output_file = f"exports/instagram_spots_validated_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    bp.export_spots_data(spots, output_file)

    # Show metrics
    metrics = bp.validate_scraping_metrics(spots)
    logger.info(f"\n\nüìä Scraping Metrics:")
    logger.info(f"  Location Detection Rate: {metrics['location_detection_rate']:.1f}%")
    logger.info(f"  Coordinate Accuracy: {metrics['coordinate_accuracy']:.1f}%")
    logger.info(f"  Occitanie Coverage: {metrics['occitanie_coverage']:.1f}%")

    logger.info("\nüí° Key Features:")
    logger.info("‚úÖ Includes required 'source' field for schema validation")
    logger.info("‚úÖ Detects activities from caption text")
    logger.info("‚úÖ Performs sentiment analysis")
    logger.info("‚úÖ Validates coordinates within Occitanie bounds")
    logger.info("‚úÖ Export format ready for JSON schema validation")


if __name__ == "__main__":
    main()
